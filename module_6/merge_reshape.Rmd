---
title: "Merges and Reshapes"
output: html_document
---

In addition to the data manipulation gymnastics we learned last week, there are two other core tools you should have in your data wrangling toolkit: *merging* two datasets together, and *reshaping* datasets into a different format. 

As always, I start out by loading some relevant libraries:
```{r}
library(data.table)
```
<br> 
## Merging
Let's say I have two datasets about students' test scores, named `scores_exam_1` and `scores_exam_2`:
```{r}
## note: this is how you make a data.table from scratch! The values to the left of the "=" are column names, the vectors to the right are the values. You should recognize most of these functions, except "sample". Type ?sample into your console to learn what it does.
scores_exam_1 <- data.table(class_section=c(rep("A", 5), rep("B", 6)),
                            student_id=c(1:5, 1:6),
                            score_1=sample(70:100, 11, replace=T))
print(scores_exam_1)

scores_exam_2 <- data.table(class_section=c(rep("A", 5), rep("B", 6)),
                            student_id=c(1:5, 1:6),
                            score_2=sample(70:100, 11, replace=T))
print(scores_exam_2)
```

<br>
I'd like to make these into a single dataset so that I can (for example) take the difference between the two test scores for each student, or plot one test score against the other. How can I do this? Using the `merge()` command, of course!

Let's take a look back up at our datasets. Each one has three columns: `student_id`, `class_section`, and some sort of "score" variable. The `student_id` and `class_section` variables are the same in each dataset, while the "score" variable has both a *different name* and *different values*. What we'd like to end up with is a dataset with *four* variables: `student_id`, `class_section`, `score_1`, and `score_2`:
```{r, echo=F}
merge(scores_exam_1, scores_exam_2, by=c("class_section", "student_id"))
```

`merge()` takes three main arguments: `x`, `y`, and `by`. `x` and `y` are the datasets you want to merge together, while `by` is a vector of the column names the two datasets have in *common*. This is how R knows which row to line up with which in any given dataset. So, to merge my two datasets together, I would do: 
```{r}
merge(scores_exam_1, scores_exam_2, by=c("class_section", "student_id"))
```
<br>
Notice that I need to include *both* `class_section` and `student_id` in order to effectively merge my dataset, because it's only the *combination of those two* that uniquely identify a student. Let's see what happens when I try to merge with just one of those columns:
```{r, error=T}
merge(scores_exam_1, scores_exam_2, by=c("student_id"))
```
<br>
Whoa, that's not what we wanted! That's some weird mix of stacking and merging and it's not useful. Be careful! 

There's one more argument type you should be aware of in `merge()`: the `all`, `all.x`, and `all.y` arguments. To understand why they're useful, let's say that a new class section was added between exams 1 and 2, so you `scores_exam_2` actually looks like this:
```{r}
scores_exam_2 <- data.table(class_section=c(rep("A", 5), rep("B", 6), rep("C", 4)),
                            student_id=c(1:5, 1:6, 1:4),
                            score_2=sample(70:100, 15, replace=T))
print(scores_exam_2)
```
<br>
By default, the `merge` command will keep *only rows that are found in both datasets*. So running the `merge` command we ran before will get us the same outcome we had before:
```{r}
merge(scores_exam_1, scores_exam_2, by=c("class_section", "student_id"))
```
<br>
But what if we wanted to keep the rows from `scores_exam_2`, and just fill in with missing values for exam 1 scores? We could do that by instructing `merge` to keep *all* the rows from the *y* dataset, by setting the argument `all.y` equal to `TRUE`:
```{r}
merge(scores_exam_1, scores_exam_2, by=c("class_section", "student_id"), all.y=TRUE)
```
<br>
Now let's imagine that additionally, there's a student in section A (id number 6) who dropped after the first exam, so he doesn't show up in dataset 2:
```{r}
scores_exam_1 <- data.table(class_section=c(rep("A", 6), rep("B", 6)),
                            student_id=c(1:6, 1:6),
                            score_1=sample(70:100, 12, replace=T))

print(scores_exam_1)
```
<br>
You can include *just* this extra student (and nobody in section C from the other dataset), by running the `merge` command with `all.x` equal to `TRUE`. Or, if you wanted to keep all the extra rows, you could run with both `all.x` and `all.y` equal to `TRUE`. It's common enough to want to do this that `merge` has an `all` argument that, when set to `TRUE`, is equivalent to setting both `all.x` and `all.y` equal to  `TRUE`. Try it yourself!


## Reshaping
Let's go ahead and actually make a new dataset that merges the original `scores_exam_1` and `scores_exam_2`
```{r, echo=F}
scores_exam_1 <- data.table(class_section=c(rep("A", 5), rep("B", 6)),
                            student_id=c(1:5, 1:6),
                            score_1=sample(70:100, 11, replace=T))

scores_exam_2 <- data.table(class_section=c(rep("A", 5), rep("B", 6)),
                            student_id=c(1:5, 1:6),
                            score_2=sample(70:100, 11, replace=T))
```

```{r}
scores <- merge(scores_exam_1, scores_exam_2, by=c("class_section", "student_id"))
print(scores)
```
<br>
What if I wanted a new column with the mean score for each exam, by class section? I could do this:
```{r, eval=F}
scores[, mean_score_1:= mean(score_1), by=list(class_section)]
scores[, mean_score_2:=mean(score_2), by=list(class_section)]
```
<br>

...But then I'd be repeating myself, and I hate doing that. It would be great if, instead, I could combine both of the "score" columns into a single column, with a new column to identify which exam they came from:
```{r, echo=F}
melt(scores, id.vars=c("student_id", "class_section"), variable.name="exam", value.name="score")
```
If my dataset were in that format, I could just run one quick "by" command and be done with it! (Test yourself: what command would I run on the dataset above to get the mean score by exam and class section?) 

### Melting

Any time you want to change the shape of your dataset, either by making multiple columns into one column or by making one column into several, it's called a **reshape** operation. The type of reshape we're describing here, where several columns become a single column, is called a **melt** or a **reshape long**. They work using the `melt` command from the `data.table` package:
```{r}
melt(data=scores, id.vars=c("student_id", "class_section"))
```
<br>
The `melt` function requires two arguments: `data`, the dataset you want to reshape, and `id.vars`, a vector of all the column names you want to *keep as they are*. By default, every column that is not included in `id.vars` will get reshaped (though you can change this with the `measure.vars` argument). 

`melt` produces a dataset with `n` + 2 columns, where `n` is the number of columns you included in `id.vars`. The additional two columns are named `variable` and `value`. `variable` contains the column names of the (former) columns that you have since reshaped into rows, while `value` contains all the elements that used to be in those columns. You can see this clearly in the dataset above: the `value` column is just the `score_1` and `score_2` columns from the original `scores` dataset stacked on top of each other, while the `variable` column identifies which of the original columns (`score_1` or `score_2`) that datapoint came from. 

If you don't want your new columns to be named `variable` and `value`, you can change those names with the `variable.name` and `value.name` arguments to `melt`, respectively. That's what I did in my original example of a reshaped dataset. 

Let's look at another example-- a real-life dataset from the `MASS` library, about nutritional value of US cereals. Let's start by loading in the data and doing a little cleaning (remember to install the `MASS` dataset if you haven't already!)
```{r, results='hide'}
library(MASS)
data(UScereal) # load UScereal dataset
UScereal$cereal_name <- rownames(UScereal) # this saves the names of cereals as an actual row, instead of an index value. not super important right now.
UScereal <- data.table(UScereal) # convert to a data.table
UScereal[, shelf:=NULL] # we won't need that column
UScereal[, sodium:= sodium/1000] # this converts the units of the "sodium" column from milligrams to grams
```
```{r}
print(head(UScereal))
```
<br>
As we can see, this dataset has multiple columns. `cereal_name` is the name brand of the cereal, `mfr` is the first initial of the manufacturer, `vitamins` is the vitamin/mineral content of the cereal (equal to either "none", "enriched", or "100%"), and all the other columns are numeric. Most of these represent the grams of protein, fat, etc. in one portion of cereal, while `calories` indicates the calories in one portion of cereal. 
What if we wanted to reshape this dataset so that all the numeric values were in one column? This would leave only the `cereal_name`, `mfr`, and `vitamins` columns separate. Try to work it out yourself before looking at the solution.

Ready?

To reshape this dataset as described, you would do:
```{r}
melt(UScereal, id.vars=c("cereal_name", "mfr", "vitamins"))
```
<br>
Does that make sense? every column I put in the `id.vars section stays separate, while the rest get compressed into just two columns. So now, if I wanted to (for example) take the mean value of every different type of nutritional factor across all cereals, I wouldn't have to write out eight new column names. I could just do: 
```{r}
# save the melted dataset to a new data.frame object so we can make further changes
melted_UScereal <- melt(UScereal, id.vars=c("cereal_name", "mfr", "vitamins"))
melted_UScereal[, list(mean_value=mean(value)), by=list(variable)]
```
<br>
Put on your "data scientist" hat for a minute and look at this result. Does anything strike you as strange? Remember, I said before that every value in that list, except for calories, should count how many *grams* of each different nutritional component there are in *one serving* of cereal. 

Hopefully you noticed that the mean `potassium` value is far, far higher than it should be. Most servings of cereal don't even weight 100 grams, so how could they have on average 160 grams of potassium? 

This is a mistake in the documentation-- if you do `?UScereal` you'll see that the description of the dataset claims that the `potassium` column has units of grams, but it's almost certainly in milligrams instead. If you've been following along, you've noticed that we already converted one column in the dataset from units of milligrams to units of grams-- how can you change your code to do the same thing for potassium?

It's extremely common in data science not to notice mistakes or discrepancies like these right away-- I honestly didn't catch the potassium thing until I looked at the means of those reshaped results. (Visualization is another great way to catch weird things in your data, we'll talk about that next lecture). This is one of many reasons why writing *scripts* is so important-- it allows you to go back and make a change in your workflow without having to rewrite all the steps that came after it. 

Ok, I've droned on for a *long* time about melting now-- take a break, watch a gif of this cute animal, and let's come back to have a discussion about melting's sister operation, **casting**. 

### Casting





